{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitvenvvenveef80181f8424b6d9887d26b5aa3ea0b",
   "display_name": "Python 3.7.6 64-bit ('.venv': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data.\n",
    "def get_dfs():\n",
    "    return pd.read_csv('..\\Data\\credit_card_default_train.csv'), \\\n",
    "           pd.read_csv('..\\Data\\credit_card_default_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean & transform dataframe.\n",
    "def del_columns(df, columns):\n",
    "    for column in columns:\n",
    "        del df[column]\n",
    "    return df\n",
    "\n",
    "def label_encoder(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].astype('category')\n",
    "    \n",
    "    cat_columns = df.select_dtypes(['category']).columns\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    return df\n",
    "\n",
    "def one_hot_encoder(df, columns):\n",
    "    for column in columns:\n",
    "        dummies = pd.get_dummies(df[column], prefix=column, drop_first=False).astype('int64')\n",
    "        del df[column]\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df\n",
    "\n",
    "def age_encoder(df, columns):\n",
    "    for i, column in enumerate(columns, 1):\n",
    "        df['Age_'+str(i)] = df[column].replace(['Less than 30','31-45', '46-65', 'More than 65'],\n",
    "                                               [0, 1, 2, 3])\n",
    "        del df[column]\n",
    "    return df\n",
    "    \n",
    "def str_to_currency(df, columns):\n",
    "    for i, column in enumerate(columns, 1):\n",
    "        df['Limit_'+str(i)] = (df[column].replace(r'[KM]+$', '', regex=True).astype(float) * \\\n",
    "                               df[column].str.extract(r'[\\d\\.]+([KM]+)', expand=False)\n",
    "                                         .fillna(1)\n",
    "                                         .replace(['K','M'], [10**3, 10**6]).astype(int))\n",
    "        del df[column]\n",
    "    return df\n",
    "\n",
    "def one_hot_cat_column(feature_name, vocab):\n",
    "    return tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    df.set_index('Client_ID', inplace=True)\n",
    "    df = age_encoder(df, ['AGE'])\n",
    "    df = str_to_currency(df, ['Balance_Limit_V1'])\n",
    "    return df\n",
    "\n",
    "X_train, X_test = map(preprocess_df, get_dfs())\n",
    "y_train = X_train.pop('NEXT_MONTH_DEFAULT')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = ['Gender', 'EDUCATION_STATUS', 'MARITAL_STATUS']\n",
    "NUMERIC_COLUMNS = ['Age_1', 'Limit_1', 'PAY_JULY', 'PAY_AUG', 'PAY_SEP', 'PAY_OCT', 'PAY_NOV', 'PAY_DEC',\n",
    "                   'DUE_AMT_JULY', 'DUE_AMT_AUG', 'DUE_AMT_SEP', 'DUE_AMT_OCT', 'DUE_AMT_NOV', 'DUE_AMT_DEC',\n",
    "                   'PAID_AMT_JULY', 'PAID_AMT_AUG', 'PAID_AMT_SEP', 'PAID_AMT_OCT', 'PAID_AMT_NOV', 'PAID_AMT_DEC']\n",
    "FEATURE_COLUMNS = []\n",
    "\n",
    "for feature in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = X_train[feature].unique()\n",
    "    FEATURE_COLUMNS.append(one_hot_cat_column(feature, vocabulary))\n",
    "\n",
    "for feature in NUMERIC_COLUMNS:\n",
    "    FEATURE_COLUMNS.append(tf.feature_column.numeric_column(feature, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(X, y=None, n_epochs=None, batch=32, shuffle=True):\n",
    "    def input_fn():\n",
    "        if y is None:\n",
    "            dataset = tf.data.Dataset.from_tensor_slices(X.to_dict(orient='list'))\n",
    "        else:\n",
    "            dataset = tf.data.Dataset.from_tensor_slices((X.to_dict(orient='list'), y))\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(1000)\n",
    "        dataset = (dataset.repeat(n_epochs)\n",
    "                          .batch(batch))\n",
    "        return dataset\n",
    "    return input_fn\n",
    "\n",
    "# Training and evaluation input functions.\n",
    "train_input_fn = make_input_fn(X_train, y_train)\n",
    "val_input_fn = make_input_fn(X_val, y_val, shuffle=False, n_epochs=1)\n",
    "test_input_fn = make_input_fn(X_test, shuffle=False, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy</th>\n      <td>0.222500</td>\n    </tr>\n    <tr>\n      <th>accuracy_baseline</th>\n      <td>0.778056</td>\n    </tr>\n    <tr>\n      <th>auc</th>\n      <td>0.499462</td>\n    </tr>\n    <tr>\n      <th>auc_precision_recall</th>\n      <td>0.221759</td>\n    </tr>\n    <tr>\n      <th>average_loss</th>\n      <td>9133.829102</td>\n    </tr>\n    <tr>\n      <th>label/mean</th>\n      <td>0.221944</td>\n    </tr>\n    <tr>\n      <th>loss</th>\n      <td>9120.820312</td>\n    </tr>\n    <tr>\n      <th>precision</th>\n      <td>0.221758</td>\n    </tr>\n    <tr>\n      <th>prediction/mean</th>\n      <td>0.998610</td>\n    </tr>\n    <tr>\n      <th>recall</th>\n      <td>0.997497</td>\n    </tr>\n    <tr>\n      <th>global_step</th>\n      <td>10.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                0\naccuracy                 0.222500\naccuracy_baseline        0.778056\nauc                      0.499462\nauc_precision_recall     0.221759\naverage_loss          9133.829102\nlabel/mean               0.221944\nloss                  9120.820312\nprecision                0.221758\nprediction/mean          0.998610\nrecall                   0.997497\nglobal_step             10.000000"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = tf.estimator.DNNClassifier(feature_columns=FEATURE_COLUMNS,\n",
    "                                 hidden_units=[10, 5])\n",
    "est.train(train_input_fn, max_steps=10)\n",
    "\n",
    "# Evaluation.\n",
    "results = est.evaluate(val_input_fn)\n",
    "clear_output()\n",
    "pd.Series(results).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "INFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from C:\\Users\\TRABEY~1\\AppData\\Local\\Temp\\tmpj31g6sna\\model.ckpt-10\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\n"
    }
   ],
   "source": [
    "y_pred = np.array([np.argmax(p['probabilities']) for p in est.predict(test_input_fn)])\n",
    "y_test = pd.DataFrame(y_pred, columns=['NEXT_MONTH_DEFAULT'], index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv('..\\Day 3\\Outputs\\DNNClassifier_Pred.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns_colors = sns.color_palette('colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\TRABEY~1\\\\AppData\\\\Local\\\\Temp\\\\tmp_ohbux4w', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from C:\\Users\\TRABEY~1\\AppData\\Local\\Temp\\tmp_ohbux4w\\model.ckpt-50\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\n"
    }
   ],
   "source": [
    "pred_dicts = list(est.experimental_predict_with_explanations(val_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DFC Pandas dataframe.\n",
    "labels = y_val.values\n",
    "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
    "df_dfc = pd.DataFrame([pred['dfc'] for pred in pred_dicts])\n",
    "df_dfc.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of DFCs + bias == probabality.\n",
    "bias = pred_dicts[0]['bias']\n",
    "dfc_prob = df_dfc.sum(axis=1) + bias\n",
    "np.testing.assert_almost_equal(dfc_prob.values, probs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate code for plotting :)\n",
    "def _get_color(value):\n",
    "    \"\"\"To make positive DFCs plot green, negative DFCs plot red.\"\"\"\n",
    "    green, red = sns.color_palette()[2:4]\n",
    "    if value >= 0: return green\n",
    "    return red\n",
    "\n",
    "def _add_feature_values(feature_values, ax):\n",
    "    \"\"\"Display feature's values on left of plot.\"\"\"\n",
    "    x_coord = ax.get_xlim()[0]\n",
    "    OFFSET = 0.15\n",
    "    for y_coord, (feat_name, feat_val) in enumerate(feature_values.items()):\n",
    "        t = plt.text(x_coord, y_coord - OFFSET, '{}'.format(feat_val), size=12)\n",
    "        t.set_bbox(dict(facecolor='white', alpha=0.5))\n",
    "    from matplotlib.font_manager import FontProperties\n",
    "    font = FontProperties()\n",
    "    font.set_weight('bold')\n",
    "    t = plt.text(x_coord, y_coord + 1 - OFFSET, 'feature\\nvalue',\n",
    "    fontproperties=font, size=12)\n",
    "\n",
    "def plot_example(example):\n",
    "  TOP_N = 8 # View top 8 features.\n",
    "  sorted_ix = example.abs().sort_values()[-TOP_N:].index  # Sort by magnitude.\n",
    "  example = example[sorted_ix]\n",
    "  colors = example.map(_get_color).tolist()\n",
    "  ax = example.to_frame().plot(kind='barh',\n",
    "                          color=[colors],\n",
    "                          legend=None,\n",
    "                          alpha=0.75,\n",
    "                          figsize=(10,6))\n",
    "  ax.grid(False, axis='y')\n",
    "  ax.set_yticklabels(ax.get_yticklabels(), size=14)\n",
    "\n",
    "  # Add feature values.\n",
    "  _add_feature_values(X_val.iloc[ID][sorted_ix], ax)\n",
    "  return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results.\n",
    "ID = 1\n",
    "example = df_dfc.iloc[ID]  # Choose ith example from evaluation set.\n",
    "TOP_N = 8  # View top 8 features.\n",
    "sorted_ix = example.abs().sort_values()[-TOP_N:].index\n",
    "ax = plot_example(example)\n",
    "ax.set_title('Feature contributions for example {}\\n pred: {:1.2f}; label: {}'.format(ID, probs[ID], labels[ID]))\n",
    "ax.set_xlabel('Contribution to predicted probability', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate plotting code.\n",
    "def dist_violin_plot(df_dfc, ID):\n",
    "  # Initialize plot.\n",
    "  fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "  # Create example dataframe.\n",
    "  TOP_N = 8  # View top 8 features.\n",
    "  example = df_dfc.iloc[ID]\n",
    "  ix = example.abs().sort_values()[-TOP_N:].index\n",
    "  example = example[ix]\n",
    "  example_df = example.to_frame(name='dfc')\n",
    "\n",
    "  # Add contributions of entire distribution.\n",
    "  parts=ax.violinplot([df_dfc[w] for w in ix],\n",
    "                 vert=False,\n",
    "                 showextrema=False,\n",
    "                 widths=0.7,\n",
    "                 positions=np.arange(len(ix)))\n",
    "  face_color = sns_colors[0]\n",
    "  alpha = 0.15\n",
    "  for pc in parts['bodies']:\n",
    "      pc.set_facecolor(face_color)\n",
    "      pc.set_alpha(alpha)\n",
    "\n",
    "  # Add feature values.\n",
    "  _add_feature_values(X_val.iloc[ID][sorted_ix], ax)\n",
    "\n",
    "  # Add local contributions.\n",
    "  ax.scatter(example,\n",
    "              np.arange(example.shape[0]),\n",
    "              color=sns.color_palette()[2],\n",
    "              s=100,\n",
    "              marker=\"s\",\n",
    "              label='contributions for example')\n",
    "\n",
    "  # Legend\n",
    "  # Proxy plot, to show violinplot dist on legend.\n",
    "  ax.plot([0,0], [1,1], label='eval set contributions\\ndistributions',\n",
    "          color=face_color, alpha=alpha, linewidth=10)\n",
    "  legend = ax.legend(loc='lower right', shadow=True, fontsize='x-large',\n",
    "                     frameon=True)\n",
    "  legend.get_frame().set_facecolor('white')\n",
    "\n",
    "  # Format plot.\n",
    "  ax.set_yticks(np.arange(example.shape[0]))\n",
    "  ax.set_yticklabels(example.index)\n",
    "  ax.grid(False, axis='y')\n",
    "  ax.set_xlabel('Contribution to predicted probability', size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_violin_plot(df_dfc, ID)\n",
    "plt.title('Feature contributions for example {}\\n pred: {:1.2f}; label: {}'.format(ID, probs[ID], labels[ID]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = est.experimental_feature_importances(normalize=True)\n",
    "df_imp = pd.Series(importances)\n",
    "\n",
    "# Visualize importances.\n",
    "N = 8\n",
    "ax = (df_imp.iloc[0:N][::-1]\n",
    "    .plot(kind='barh',\n",
    "          color=sns_colors[0],\n",
    "          title='Gain feature importances',\n",
    "          figsize=(10, 6)))\n",
    "ax.grid(False, axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot.\n",
    "dfc_mean = df_dfc.abs().mean()\n",
    "N = 8\n",
    "sorted_ix = dfc_mean.abs().sort_values()[-N:].index  # Average and sort by absolute.\n",
    "ax = dfc_mean[sorted_ix].plot(kind='barh',\n",
    "                       color=sns_colors[1],\n",
    "                       title='Mean |directional feature contributions|',\n",
    "                       figsize=(10, 6))\n",
    "ax.grid(False, axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE = 'PAY_JULY'\n",
    "feature = pd.Series(df_dfc[FEATURE].values, index=X_val[FEATURE].values).sort_index()\n",
    "ax = sns.regplot(feature.index.values, feature.values, lowess=True)\n",
    "ax.set_ylabel('contribution')\n",
    "ax.set_xlabel(FEATURE)\n",
    "ax.set_xlim(0, 100)\n",
    "plt.show()"
   ]
  }
 ]
}